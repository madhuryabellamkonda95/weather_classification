# -*- coding: utf-8 -*-
"""weather_classification_vgg16.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1FUj3EcZBdTmSrDiSZbgCaiblqJ4T9QAG
"""

from  google.colab import drive
import zipfile
drive.mount("/content/gdrive")

cd /content/gdrive/My\ Drive/

z=zipfile.ZipFile("Multi-class_Weather_Dataset.zip","r")
z.extractall("/tmp/")
z.close()

ls

ls/tmp/

import numpy as np
import cv2
import os
from imutils import paths
from sklearn.metrics import confusion_matrix
from sklearn.preprocessing import LabelEncoder
import tensorflow
from keras.applications.resnet50 import ResNet50, preprocess_input
import tensorflow.keras as keras
import keras
from keras.models import Sequential, Model
from keras.layers import Dense, Dropout, Flatten
from keras.layers import Conv2D, MaxPooling2D,Activation, MaxPooling3D, GlobalAveragePooling2D, GlobalAveragePooling3D, BatchNormalization
from keras.preprocessing import image
from keras.preprocessing.image import  ImageDataGenerator
from keras.layers import merge, Input
import random
import matplotlib.pyplot as plt
from keras.utils import to_categorical
from keras.optimizers import SGD,Adam
import numpy as np
from keras.preprocessing import image
from keras.applications.imagenet_utils import preprocess_input
from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import train_test_split
import tensorflow.keras as keras
import keras
from keras.models import Sequential, Model
from keras.layers import Dense, Dropout, Flatten
from keras.layers import Conv2D, MaxPooling2D,Activation
import time
from keras.applications.vgg16 import VGG16
from keras.applications.resnet50 import ResNet50
from keras.preprocessing.image import  ImageDataGenerator
from keras.layers import merge, Input
from keras import regularizers

#loading images


path= "/tmp/Multi-class_Weather_Dataset/"

def load_data(path):
  img_paths=list(paths.list_images(path))
  images,labels=[],[]
  for i in img_paths:
    imgs=cv2.imread(i)
    if imgs is not None:
      imgs=cv2.resize(imgs,(224,224), )
      imgs=imgs/255
      images.append(imgs)
      labels.append(i.split(os.path.sep)[-2])
    
  return images, labels

"""train-test-split"""

def train_test_spliting(images,labels, test_size=0.2,random_state=29):
  return train_test_split(images,labels,test_size=test_size,random_state=random_state)

"""model buiding"""

def model_building():
  model = VGG16(input_tensor=image_input, include_top=True,weights='imagenet')
  model.get_layer('fc1').kernel_regularizer = regularizers.l2(0.02)
  last_layer = model.get_layer('fc1').output
  last_layer = model.get_layer('fc2').output
  #x= Flatten(name='flatten')(last_layer)
  out = Dense(num_classes, activation='softmax', name='output')(last_layer)
  custom_vgg_model = Model(image_input, out)
  return  custom_vgg_model

"""label encoding"""

path="/tmp/Multi-class_Weather_Dataset"
images,labels = load_data(path)
labels=np.array(labels)
images = np.array(images)
print(len(images),len(labels))
lb=LabelEncoder()
enc_labels=lb.fit_transform(labels)
print(lb.classes_)
num_classes = len(lb.classes_)
x_train,x_test,y_train,y_test=train_test_split(images,enc_labels,test_size=0.2,random_state=42)

"""input shape of images"""

image_input = Input(shape=(224, 224, 3))

"""data augmentation"""

datagen = ImageDataGenerator(
    featurewise_center=False,  # set input mean to 0 over the dataset
    samplewise_center=False,  # set each sample mean to 0
    featurewise_std_normalization=False,  # divide inputs by std of the dataset
    samplewise_std_normalization=False,  # divide each input by its std
    zca_whitening=False,  # apply ZCA whitening
    rotation_range=45,  # randomly rotate images in the range (degrees, 0 to 180)
    width_shift_range=0.2,  # randomly shift images horizontally (fraction of total width)
    height_shift_range=0.2,  # randomly shift images vertically (fraction of total height)
    horizontal_flip=True,  # randomly flip images
    vertical_flip=False)  # randomly flip images

"""summary of model"""

model = model_building()
print(model.summary())
for layer in model.layers[:-1]:
	layer.trainable = False

"""compile and training"""

model.compile(loss='sparse_categorical_crossentropy',optimizer='adam',metrics=['accuracy'])
t=time.time()
hist=model.fit_generator(datagen.flow(x_train, y_train, batch_size = 64),epochs=50,shuffle=True,validation_data=(x_test,y_test ))

print('Training time: %s' % (t - time.time()))
(loss, accuracy) = model.evaluate(x_test, y_test, batch_size=16, verbose=1)

print("[INFO] loss={:.4f}, accuracy: {:.4f}%".format(loss,accuracy * 100))

"""plots of accuracy and loss"""

import matplotlib.pyplot as plt
def show_history(history):
    plt.plot(history.history['accuracy'])
    plt.plot(history.history['val_accuracy'])
    plt.ylabel('accuracy')
    plt.xlabel('epoch')
    plt.legend(['train_accuracy', 'test_accuracy'], loc='best')
    plt.show()

show_history(hist)

def show_history(history):
    plt.plot(history.history['loss'])
    plt.plot(history.history['val_loss'])
    plt.ylabel('loss')
    plt.xlabel('epoch')
    plt.legend(['train_loss', 'test_loss'], loc='best')
    plt.show()

show_history(hist)

"""predictions"""

pred=model.predict(x_test)
print(lb.classes_[list(pred[40]).index(max(pred[40]))])
lb.classes_[y_test[40]]

model.save('weather_classification_vgg16.h5')
print('saved model to disk')

"""saving the model with h5 extension"""

import numpy as np
from keras.models import load_model
from keras.preprocessing import image
from sklearn.metrics import confusion_matrix

"""confusion matrix"""

results_for_conf_matrix = model.predict(x_test)
results_for_conf_matrix

results = []
for i in range(len(results_for_conf_matrix)):
  results.append(list(results_for_conf_matrix[i]).index(max(results_for_conf_matrix[i])))
cm=confusion_matrix(y_test, results)
cm
class_names=['Cloudy' ,'Rain' ,'Sun_shine','Sunrise']

"""accuracy_score"""

from sklearn.metrics import accuracy_score
accuracy_score(y_test, results)

"""confusion matrix without normalisation"""

def plot_confusion_matrix(cm, classes,
                          normalize=False,
                          title=None,
                          cmap=plt.cm.Blues):

    if not title:
        if normalize:
            title = 'Normalized confusion matrix'
        else:
            title = 'Confusion matrix, without normalization'

    #Compute confusion matrix
    #cm = confusion_matrix(y_true, y_pred)
    if normalize:
        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]
        print("Normalized confusion matrix")
    else:
        print('Confusion matrix, without normalization')

#print(cm)

    fig, ax = plt.subplots(figsize=(7,7))
    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)
    ax.figure.colorbar(im, ax=ax)
    # We want to show all ticks...
    ax.set(xticks=np.arange(cm.shape[1]),
           yticks=np.arange(cm.shape[0]),
           # ... and label them with the respective list entries
           xticklabels=classes, yticklabels=classes,
           title=title,
           ylabel='True label',
           xlabel='Predicted label')


    #Rotate the tick labels and set their alignment.
    plt.setp(ax.get_xticklabels(), rotation=45, ha="right",
             rotation_mode="anchor")
    # Loop over data dimensions and create text annotations.
    fmt = '.2f' if normalize else 'd'
    thresh = cm.max() / 2.
    for i in range(cm.shape[0]):
        for j in range(cm.shape[1]):
            ax.text(j, i, format(cm[i, j], fmt),
                    ha="center", va="center",
                    color="white" if cm[i, j] > thresh else "black")
    fig.tight_layout()
    return ax

np.set_printoptions(precision=2)
plot_confusion_matrix(cm, classes = class_names, title='Confusion matrix, without normalization')

"""normalised confusion matrix"""

#Plotting normalized confusion matrix
plot_confusion_matrix(cm, classes = class_names, normalize = True, title = 'Normalized confusion matrix')

import numpy as np
from keras.models import load_model
from keras.preprocessing import image
from sklearn.metrics import confusion_matrix

import numpy as np
from keras.models import load_model
from keras.preprocessing import image

ls/tmp/Multi-class_Weather_Dataset/

"""Testing the predictions"""

test_image = image.load_img(r'/tmp/Multi-class_Weather_Dataset/Sun_shine/shine2.jpg', target_size = (224, 224))

test_image = image.img_to_array(test_image)

test_image = np.expand_dims(test_image, axis = 0) #flattening
model=load_model('weather_classification_vgg16.h5') #sending data to the model for preditiopn
result = model.predict(test_image)
print(result)

print('{:.4f}%'.format(result[0][0]*100 ))
print('{:.4f}%'.format(result[0][1]*100 ))
print('{:.4f}%'.format(result[0][2]*100 ))
print('{:.4f}%'.format(result[0][3]*100 ))

if (result[0][0]*100) >= 50:
    prediction = 'Cloudy'
    print(prediction)
elif (result[0][1]*100) >= 50:
    prediction = 'Rain'
    print(prediction)
elif (result[0][2]*100) >= 50:
    prediction = 'Sun_shine'
    print(prediction)
elif (result[0][3]*100) >= 50:
    prediction = 'Sunrise'
    print(prediction)



